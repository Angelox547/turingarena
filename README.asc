= TaskWizard - Create algorithmic challanges

TaskWizard lets you define a problem which requires an algorithmic solution,
and then automatically test the code of any provided solution.

== Getting started

Clone or download the repository (follow GitHub instruction)
and `cd` into the cloned/download folder.

To build/install, run

    sh build/scripts.sh

and follow instructions.

Then, `cd` into folder `tests/aplusb` which contains an example problem and run

    taskmake prepare
    echo "call evaluate 3 5 return" | taskrun solution:aplusb.cpp
    
The first line prepares the problem.
The second line run evaluates the solution aplusb.cpp,
with parameters `3 5`.
You can see the line `return 1` on the standard output
indicating that the solution solves this case correctly.
By providing an incorrect solution, the line is `return 0`
instead.

== Goals

* Writing a solution should require little-to-no usage of low-level primitives,
  not even reading/writing from a file/stdin/stdout.
  
* Defining a problem should require a knowledge as similar as possible to that
  required for writing solutions.
  
* A problem can accept more than one solution at a time,
  written by different people,
  that can be evaluated together or against each other.
  
* Many programming languages should be supported,
  both for defining problems and for writing solutions,
  allowing different languages to interoperate during the evaluation.
  (Say, a problem written in python can be used to test a solution written in C,
  two solutions written in C and Java can be evaluated against each other, etc.)

== How to define a problem

At the very least, a problem must define:

* the interface that solution algorithms are required to implement 
* the logic used to evaluate solutions.

The first point is done by writing a file `task.txt`,
in a simple C-like syntax, which defines the interface.

The second point is done by writing a program (called _driver_),
in the programming language of choice,
which tests a solution.
For writing the driver, a library of tools is provided
which allows to:

* run the code of a solution in a new (sandboxed) process
* limit the time and memory usage of solutions
* invoke functions defined in a solution and receive back data
* let the solutions invoke callbacks defined in the driver

These tools are in part provided by TaskWizard,
in part generated automatically from the `task.txt` file.

== Problem definition concepts

Interface::
  Interfaces specify which functions an algorithm should implement,
  which functions (callbacks) it can use, and the type of data
  it can exchange.

Algorithm::
  An algorithm is an implementation of an interface.
  An algorithm is usually defined as the solution of a problem,
  but can be also defined by the problem writer herself.
  To define an algorithm, a single file of source code is required.
  In general, there may be more than one algorithm
  that implements the same interface at a time.

Driver::
  A program defined by the problem writer,
  which tests one or more algorithms.
  A driver can be defined with a single file of source code.
  
Process::
  A process is the execution of an Algorithm, started by a driver.
  More than one process can be started by a driver,
  even for the same algorithm.
  Each process runs in a separate sandbox:
  that is, it has its own memory, which is not shared
  with other processes.

Evaluation Phase::
  It specifies a driver to run,
  the collection of algorithms that the driver can use
  (indicating whether they are given as part of the solution,
  or if they are defined in the problem itself),
  the collection of data that the driver can read
  (indicating whether they are given as part of the solution
  or if they have been generated by other phases)
  and the collection of data the the driver should generate and save.

Parameter::
  A collection of data that is provided to the driver
  during an evaluation phase.
  Sent to driver `stdin`.

Summary::
  Main data generated by a driver in an evaluation phase.
  Output by the driver on `stdout`.

Evaluation::
  A sequence of evaluation phases.

Testcase::
  Specifies, for all the phases of an evaluation,
  the parameter to pass to the driver.

== TaskWizard internal concepts

Interface Support::
  Libraries and code generated by TaskWizard to compile and run
  any algorithm implementing a given interface.
  The support is automatically generated for every interface
  and for every programming language.
  The support for an interface is reused by all the algorithms
  implementing that interface (say, different solutions).
  
Driver Support::
  Libraries and code generated by TaskWizard to compile and run a driver.
  The driver support is automatically generated for each driver
  (only for the specific programming language used to define that driver)
  and is combined with the driver source code.

Supervisor::
  A program, part of TaskWizard, which manages the execution
  of an evaluation phase.
  The supervisor runs the driver in a sandbox,
  and communicates with it via named pipes.
  It receives instructions from the driver to start/stop processes,
  and to open files for reading and writing.
  It manages the communication between driver and processes.

Control Request Pipe::
  A pipe where a driver writes command for the supervisor
  (read from the supervisor).

Control Response Pipe::
  A pipe where the supervisor writes responses to driver requests
  (read from the driver). 

Process Downward Pipe::
  A pipe where the driver writes and a process reads.

Process Upward Pipe::
  A pipe where a process writes and the driver reads.

Driver Sandbox::
  Folder where a driver is run.
  It is created and managed by the supervisor.
  It contains the following files
  (`<id>` is replaced by the specific process/file id,
  as returned by the supervisor in the response):
  
  * `control_request.pipe`
  * `control_response.pipe`
  * `process_downward.<id>.pipe`
  * `process_upward.<id>.pipe`
  * `read_file.<id>.txt`
  * `write_file.<id>.txt`

Phase Execution Folder::
  The folder containing stuff related to the execution
  of a _single evaluation phase_ of a _single test case_.
  The supervisor starts in this folder.
  It contains the following:
  
  * `algorithms/<name>/`: algorithm `<name>`, in a ready to execute (compiled) form
  (the algorithm `<name>` is either taken from the problem definition or from a submission,
  as specified by the current execution phase)
  * `driver/`: driver associated with the current phase, in a ready to execute (compiled) form
  * `read_files/<name>/data.txt`: readable file `<name>` specified by the current phase
  * `write_files/<name>/data.txt`: writable file `<name>` specified by the current phase

Evaluation Folder::
  Folder where the results of each evaluation phase for each test case
  are collected and stored.
  It contains the following:
  
  * `testcases/<id>/phase/<phase>/summary.txt`: summary from evaluation phase `<phase>` in testcase `<id>`
  * `testcases/<id>/phase/<phase>/data/<name>/data.txt`: generated data

Problem Definition Folder::
  The folder where the problem writer defines a problem.

Problem Prepared Folder::
  A folder containing all the generated stuff associated with a problem.
  It contains the following dirs/files:
  
  * `interfaces/<name>/<lang>/`: interface support for interface `<name>` and language `<lang>`
  * `drivers/<name>/`: driver support and source code of driver `<name>`
  * `provided_algorithms/<name>/`: source sode of algorithm `<name>` (provided by the problem writer)
  * `evaluations/<name>/`: files for evaluation `<name>`
  * `evaluations/<name>/evaluation.yaml`: contains information about evaluation, such as phases
  * `evaluations/<name>/testcases/<id>/`: test case `<id>` (`<id>` can be a string, not just a number)
  * `evaluations/<name>/testcases/<id>/phases/<phase>/parameter.txt`: parameter for phase `<phase>`


